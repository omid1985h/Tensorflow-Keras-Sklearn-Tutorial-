{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5171849",
   "metadata": {},
   "source": [
    "# Pandas Comprehensive Training\n",
    "\n",
    "## 1. Introduction to Pandas\n",
    "\n",
    "Pandas is a fast, powerful, flexible, and easy-to-use open-source data analysis and manipulation library built on top of NumPy. It is commonly used in data science for cleaning, transforming, and analyzing data.\n",
    "Key components of Pandas:\n",
    "Series: 1-dimensional labeled array.\n",
    "DataFrame: 2-dimensional labeled data structure (most commonly used).\n",
    "\n",
    "\n",
    "Key Pandas Concepts for ML:\n",
    "1. Data cleaning & preprocessing (handling missing values, duplicates, etc.)\n",
    "2. Feature engineering (creating new features, encoding, normalization)\n",
    "3. Aggregation and grouping (for data summarization)\n",
    "4. Time series handling (important for forecasting)\n",
    "5. Performance optimization (working with large datasets)\n",
    "6. Data visualization integration (matplotlib, seaborn)\n",
    "    \n",
    "## 2. Basic Data Structures\n",
    "\n",
    "### 2.1 Series\n",
    "A Series is like a column in a table or a one-dimensional array with labels. You can create a Series using Python lists, NumPy arrays, or dictionaries.\n",
    "\n",
    "### 2.2 DataFrame\n",
    "A DataFrame is a two-dimensional table with labeled axes (rows and columns).\n",
    "\n",
    "## 3. Data Selection and Indexing\n",
    "\n",
    "### 3.1 Selecting Columns\n",
    "You can select columns by passing column names as a key.\n",
    "\n",
    "### 3.2 Selecting Rows by Label\n",
    "You can use .loc[] to select rows based on their index labels.\n",
    "\n",
    "### 3.3 Selecting Rows by Position\n",
    "Use .iloc[] to select rows by position (integer index).\n",
    "\n",
    "### 3.4 Conditional Selection\n",
    "You can filter the data based on conditions.\n",
    "\n",
    "### Multi-Indexing (Hierarchical Indexing)\n",
    "When dealing with large datasets, hierarchical indexing allows you to represent multi-level indices.\n",
    "\n",
    "### Indexing with .query() for Faster Selection\n",
    "The .query() method can be faster for selecting rows when compared to traditional boolean indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b01988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creating a Series from a list\n",
    "data = [10, 20, 30, 40, 50]\n",
    "series = pd.Series(data)\n",
    "print(series)\n",
    "\n",
    "\n",
    "# Creating a DataFrame from a dictionary\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Age': [25, 30, 35],\n",
    "    'City': ['New York', 'San Francisco', 'Los Angeles']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "\n",
    "# Select a single column\n",
    "age_column = df['Age']\n",
    "print(age_column)\n",
    "\n",
    "# Select multiple columns\n",
    "subset = df[['Name', 'Age']]\n",
    "print(subset)\n",
    "\n",
    "\n",
    "# Select row with label 1 (Bob)\n",
    "row_bob = df.loc[1]\n",
    "print(row_bob)\n",
    "\n",
    "# Select the first row\n",
    "first_row = df.iloc[0]\n",
    "print(first_row)\n",
    "\n",
    "# Select rows where age is greater than 30\n",
    "age_filter = df[df['Age'] > 30]\n",
    "print(age_filter)\n",
    "\n",
    ".............\n",
    "# Creating MultiIndex from arrays\n",
    "arrays = [['A', 'A', 'B', 'B'], ['one', 'two', 'one', 'two']]\n",
    "index = pd.MultiIndex.from_arrays(arrays, names=('letter', 'number'))\n",
    "df_multi = pd.DataFrame([[1, 2], [3, 4], [5, 6], [7, 8]], index=index, columns=['x', 'y'])\n",
    "print(df_multi)\n",
    "\n",
    "# Accessing data with multi-index\n",
    "print(df_multi.loc['A'])\n",
    ".............\n",
    "# Using query to filter rows (faster for large datasets)\n",
    "df_filtered = df.query('Age > 30 and City == \"New York\"')\n",
    "print(df_filtered)\n",
    "............"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aac4041",
   "metadata": {},
   "source": [
    "## 4. Data Cleaning\n",
    "\n",
    "### 4.1 Handling Missing Data\n",
    "Pandas provides multiple functions to deal with missing data (NaN).\n",
    "\n",
    "#### Imputing Missing Values\n",
    "- For numerical features, imputation methods like mean, median, or using model-based imputation are common.\n",
    "- For categorical features, you might fill missing values with the mode (most frequent value).\n",
    "\n",
    "#### Advanced Imputation with sklearn's SimpleImputer\n",
    "sklearn.impute.SimpleImputer offers various strategies like mean, median, or a constant value, and works well in a pipeline.\n",
    "\n",
    "#### Removing Missing Data\n",
    "If the proportion of missing data in a column is too high, it may be better to drop that column entirely.\n",
    "\n",
    "### 4.2 Renaming Columns\n",
    "You can rename columns using .rename().\n",
    "\n",
    "### 4.3 Replacing Values\n",
    "You can replace values in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fdb262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame with NaN values\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Age': [25, None, 35],\n",
    "    'City': ['New York', None, 'Los Angeles']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fill missing values with a constant value\n",
    "df_filled = df.fillna('Unknown')\n",
    "print(df_filled)\n",
    "\n",
    "# Drop rows with missing values\n",
    "df_dropped = df.dropna()\n",
    "print(df_dropped)\n",
    "\n",
    "......\n",
    "\n",
    "# Rename columns\n",
    "df_renamed = df.rename(columns={'Name': 'Full Name', 'Age': 'Years'})\n",
    "print(df_renamed)\n",
    "\n",
    ".........\n",
    "\n",
    "# Replace a specific value\n",
    "df_replaced = df.replace({'New York': 'NYC'})\n",
    "print(df_replaced)\n",
    "\n",
    ".........\n",
    "\n",
    "# Impute missing values with median (useful for numerical features)\n",
    "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
    "..........\n",
    "\n",
    "# Impute missing values in categorical column with mode\n",
    "df['City'].fillna(df['City'].mode()[0], inplace=True)\n",
    "\n",
    ".........\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Imputation for numeric features\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df['Age'] = imputer.fit_transform(df[['Age']])\n",
    "\n",
    "# Imputation for categorical features\n",
    "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "df['City'] = imputer_cat.fit_transform(df[['City']])\n",
    ".................\n",
    "# Drop columns with more than 30% missing data\n",
    "threshold = 0.3\n",
    "df_cleaned = df.dropna(thresh=len(df)*(1-threshold), axis=1)\n",
    ".............."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa33303",
   "metadata": {},
   "source": [
    "## 5. Data Transformation\n",
    "\n",
    "### 5.1 Apply Functions\n",
    "You can apply functions to columns or rows using .apply().\n",
    "\n",
    "### 5.2 Grouping Data\n",
    "You can group the data and apply functions using .groupby(). groupby() allows you to split data into groups and apply aggregate functions such as mean, sum, or count.\n",
    "\n",
    "### 5.3 Pivot Tables\n",
    "Pivot tables help you aggregate data and summarize it in a more readable format.\n",
    "\n",
    "### 5.4 Sorting Data\n",
    "You can sort the data using .sort_values().\n",
    "\n",
    "### 5.5 Merging DataFrames\n",
    "Pandas allows merging DataFrames using .merge()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1547467d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a function to a column\n",
    "df['Age in months'] = df['Age'].apply(lambda x: x * 12 if pd.notna(x) else None)\n",
    "print(df)\n",
    "\n",
    "...........\n",
    "# Group by a column and calculate mean\n",
    "grouped = df.groupby('City').mean()\n",
    "print(grouped)\n",
    "...........\n",
    "# Group by 'City' and calculate mean age\n",
    "df_grouped = df.groupby('City')['Age'].mean()\n",
    "print(df_grouped)\n",
    "\n",
    "# Multiple aggregations on multiple columns\n",
    "df_grouped_agg = df.groupby('City').agg({\n",
    "    'Age': 'mean',\n",
    "    'Sales': 'sum'\n",
    "})\n",
    "print(df_grouped_agg)\n",
    "...........\n",
    "# Creating a pivot table with multiple levels of aggregation\n",
    "pivot_table = df.pivot_table(values='Sales', index='City', columns='Age', aggfunc='mean', fill_value=0)\n",
    "print(pivot_table)\n",
    "...........\n",
    "# Sort by Age\n",
    "df_sorted = df.sort_values(by='Age')\n",
    "print(df_sorted)\n",
    "..........\n",
    "# Create another DataFrame\n",
    "data2 = {\n",
    "    'City': ['New York', 'San Francisco', 'Los Angeles'],\n",
    "    'Population': [8000000, 870000, 4000000]\n",
    "}\n",
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "# Merge dataframes on 'City'\n",
    "merged_df = pd.merge(df, df2, on='City')\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f29722e",
   "metadata": {},
   "source": [
    "## 6. Time Series Analysis\n",
    "\n",
    "Pandas is great for time series data. You can work with datetime objects for indexing and analysis.\n",
    "\n",
    "6.1 DateTime Conversion\n",
    "Ensure that date columns are in proper datetime format for time series analysis.\n",
    "\n",
    "6.2 Resampling Time Series Data\n",
    "For time series forecasting, resampling helps to aggregate data into a specific frequency.\n",
    "\n",
    "6.3 Time Series Lag Features\n",
    "Lag features help when creating predictive models for time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee68cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a time series DataFrame\n",
    "dates = pd.date_range('2024-01-01', periods=6)\n",
    "data = {'Sales': [250, 300, 350, 400, 450, 500]}\n",
    "df_time_series = pd.DataFrame(data, index=dates)\n",
    "print(df_time_series)\n",
    "\n",
    "# Resampling (e.g., monthly average)\n",
    "df_resampled = df_time_series.resample('M').mean()\n",
    "print(df_resampled)\n",
    "\n",
    ".............\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "print(df['Date'].dt.year)\n",
    "...............\n",
    "# Resample data to monthly frequency and take mean\n",
    "df_resampled = df.resample('M', on='Date').mean()\n",
    ".............\n",
    "# Lag feature (e.g., previous month's sales)\n",
    "df['Sales_lag'] = df['Sales'].shift(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cf691d",
   "metadata": {},
   "source": [
    "## 7. Feature Engineering for Machine Learning\n",
    "\n",
    "### 7.2 Creating New Features\n",
    "Sometimes new features are derived from existing ones. For example, creating interaction terms or aggregating features.\n",
    "\n",
    "### Feature Scaling (Normalization & Standardization)\n",
    "For most ML models, scaling is crucial. Use MinMaxScaler for normalization or StandardScaler for standardization.\n",
    "\n",
    "### One-Hot Encoding\n",
    "For categorical variables, one-hot encoding transforms them into binary columns.\n",
    "\n",
    "### Label Encoding for Machine Learning\n",
    "Label encoding can be used when there’s an ordinal relationship between categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b90578e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating interaction feature\n",
    "df['Age_X_City'] = df['Age'] * df['City'].astype('category').cat.codes\n",
    "\n",
    "............\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# Standardization (zero mean, unit variance)\n",
    "scaler = StandardScaler()\n",
    "df['Age_scaled'] = scaler.fit_transform(df[['Age']])\n",
    "\n",
    "# Normalization (scaling to range [0, 1])\n",
    "scaler = MinMaxScaler()\n",
    "df['Age_normalized'] = scaler.fit_transform(df[['Age']])\n",
    "\n",
    "..........\n",
    "\n",
    "# One-hot encode a categorical column (City)\n",
    "df_encoded = pd.get_dummies(df, columns=['City'], drop_first=True)\n",
    "print(df_encoded)\n",
    "\n",
    "..............\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "df['City_encoded'] = encoder.fit_transform(df['City'])\n",
    "print(df[['City', 'City_encoded']])\n",
    ".............."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874c090f",
   "metadata": {},
   "source": [
    "## 8. Pandas Integration with Machine Learning Workflows\n",
    "\n",
    "### 8.1 Data Pipeline Using sklearn.pipeline\n",
    "Creating a data pipeline helps streamline preprocessing steps before fitting the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cced0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Fit the pipeline\n",
    "pipeline.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
